{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect car damage from video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will show how to create frames from a given video, classify each frame using the pretrained classifier, annotate each frame acoordingly, and finally make a video from those annotated frames. This would be useful for damage assessment, where a user would feed a video of a damaged car as input, and the damage location/extent would be predicted instantly. This can be very beneficial for insurance companies as well as the car owners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "#! pip install pytube\n",
    "from pytube import YouTube\n",
    "#! conda install -c conda-forge imageio\n",
    "import imageio\n",
    "#! pip install moviepy\n",
    "from moviepy.editor import *\n",
    "from ipywidgets import Video\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.widgets import *\n",
    "from PIL import Image\n",
    "import hashlib\n",
    "#import scipy.misc\n",
    "#from scipy.misc import imread, imresize, imshow\n",
    "import time\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download youtube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/manas/Desktop/Kaggle projects/Video_detection'\n",
    "url = 'https://www.youtube.com/watch?v=ETtwBWe9yQc'\n",
    "save_fn = 'Damaged_car1'\n",
    "yt = YouTube(url).streams.first().download(output_path=filepath, filename=save_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Video, save to images and annotate them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "I have combined 2 models from previous training: 1st model- to differentiate between undamaged cars/out of domain images from damaged cars; 2nd model- to predict damage location. I have broadly classified into 3 damage classes, bonnet, sideways and rear. Definitely the result would imrove with larger dataset and more specific damage location. Here, the dataset is first classified with 1st learner. When any damage is detected then the image goes through the 2nd classifier and the damage type is annotated on the respective frame. A frame without damage is not annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture('C:/Users/manas/Desktop/Kaggle projects/Video_detection/Damaged_car1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_folder_path = 'C:/Users/manas/Desktop/Kaggle projects/Video_detection/Damaged_car_1_frames/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading learner objects\n",
    "learn_car = load_learner('C:/Users/manas/Desktop/Kaggle projects/cars')\n",
    "learn_dmg = load_learner('C:/Users/manas/Desktop/Kaggle projects/Car crash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmg_detect(learn, frame_path):\n",
    "    prediction = learn.predict(open_image(frame_path))\n",
    "    category = prediction[0]\n",
    "    probability = \"{0:.4f}\".format(max(prediction[2]))\n",
    "    return category, probability    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/manas/Desktop/Kaggle projects/Video_detection/Damaged_car_1_frames_text/'\n",
    "count = 0\n",
    "success = 1\n",
    "while success:\n",
    "    success,frame = vidcap.read()\n",
    "    frame_path = frame_folder_path + f'frame{count}.jpg'\n",
    "    cv2.imwrite(frame_path,frame)\n",
    "    #print(frame_path)\n",
    "    \n",
    "    # model prediction: damaged car\n",
    "    category_car, probability_car = dmg_detect(learn_car,frame_path)\n",
    "    if str(category_car) =='cars_undamaged':\n",
    "        category_damage = ''\n",
    "    else:\n",
    "        category_dmg, probability_dmg = dmg_detect(learn_dmg,frame_path)\n",
    "        category_damage = 'Damaged car: ' + str(category_dmg)\n",
    "        \n",
    "     \n",
    "     \n",
    "    # writing category text on image \n",
    "    \n",
    "    if category_damage != '':\n",
    "        #text = f'{category} \\n {probability}'\n",
    "        text = f'{category_damage}'\n",
    "\n",
    "        #Writing on iamge\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        # set the rectangle background to white\n",
    "        rectangle_bgr = (255, 255, 255)\n",
    "        # get the width and height of the text box\n",
    "        (text_width, text_height) = cv2.getTextSize(text, font, fontScale=1.0, thickness=1)[0]\n",
    "        # set the text start position\n",
    "        text_offset_x = 5\n",
    "        text_offset_y = 16\n",
    "        # make the coords of the box with a small padding (change  coordinate to adjust)\n",
    "        box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 10, text_offset_y + text_height + 10))\n",
    "        cv2.rectangle(frame, box_coords[0], box_coords[1], rectangle_bgr, cv2.FILLED)\n",
    "\n",
    "        \n",
    "        img_with_text = cv2.putText(frame,text,(10, 40),\n",
    "            font,1,(255,0,0),2,cv2.LINE_AA)\n",
    "\n",
    "        # Save the image\n",
    "\n",
    "        cv2.imwrite(filepath + f'frame{count}.jpg',img_with_text)\n",
    "\n",
    "    else:\n",
    "        cv2.imwrite(filepath + f'frame{count}.jpg',frame)\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.waitKey(1)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model sometimes confuses between bonnet and trunk due to their similar appearance. I need to train the model with even larger and carefully curated dataset to make the it more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From image to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathIn= 'C:/Users/manas/Desktop/Kaggle projects/Video_detection/Damaged_car_1_frame_text_1/'\n",
    "pathOut = 'C:/Users/manas/Desktop/Kaggle projects/Video_detection/damaged_car_text.mp4'\n",
    "fps = 20\n",
    "frame_array = []\n",
    "files = [f for f in os.listdir(pathIn)]\n",
    "\n",
    "for i in range(len(files)):\n",
    "    filename=pathIn + 'frame'+' ('+ str(i+1)+ ')'+ '.jpg'\n",
    "    \n",
    "    #reading each files\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    \n",
    "    #inserting the frames into an image array\n",
    "    frame_array.append(img)\n",
    "    \n",
    "out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "for i in range(len(frame_array)):\n",
    "    # writing to a image array\n",
    "    out.write(frame_array[i])\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and future scope of work\n",
    "\n",
    "Overall, the model did pretty good job in detecting damaged car, and its damage location. But there are still rooms for improvements.\n",
    "\n",
    "As noted earlier, I need to more data for each class to make the model more efifcient. This is  just a prototype. But to make model more useful, the structure of the model would be as follows.\n",
    "\n",
    "classifier 1:\n",
    "classes: out of domain, cars\n",
    "\n",
    "if class== 'cars',\n",
    "classifier 2:\n",
    "classes: undamaged, damaged\n",
    "\n",
    "if class == 'damaged',\n",
    "classifier 3:\n",
    "classes: bonnet, bumper, windshield, sideways, trunk, tyre etc.\n",
    "\n",
    "for each class,\n",
    "classifier 4:\n",
    "classes: major, minor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorchcpu] *",
   "language": "python",
   "name": "conda-env-pytorchcpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
